{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chicago Crime Analysis**\n",
    "\n",
    "**Author:** Meg Hutch\n",
    "\n",
    "**Date:** June 7, 2020\n",
    "\n",
    "**Data source:** Data was accessed from [data.cityofchicago](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2). \n",
    "\n",
    "As described on their website:\n",
    "> \"This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system.\"\n",
    "\n",
    "In this analysis several machine and deep learning methods are implemented to examine the utility of these advanced analytic methods in predicting crime in the city of Chicago which occured in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score, auc, precision_recall_fscore_support, f1_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "crime_df = pd.read_csv(r'C:\\\\Users\\\\User\\\\Box Sync/Projects/Chicago_Crimes/Crimes_-_2001_to_present.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Pre-Processing**\n",
    "\n",
    "Several pre-processing steps were required to work with the data. \n",
    "\n",
    "We modified the dataset as follows:\n",
    "\n",
    "1. Filter for cimes occuring in 2020\n",
    "2. Remove white space from column names\n",
    "3. Concatenate Primary_Type and Description\n",
    "4. Convert Year and Community_Area to type 'object'\n",
    "5. Remove Primary_Type categories that occured < 1000 times\n",
    "6. Remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "crime_df = crime_df[crime_df['Year'] == 2020]\n",
    "\n",
    "# Step 2\n",
    "crime_df.columns = crime_df.columns.str.replace(' ', '_')\n",
    "\n",
    "# Step 3\n",
    "crime_df[\"Primary_Type_Description\"] = crime_df[\"Primary_Type\"] + \" \" +  crime_df[\"Description\"]\n",
    "\n",
    "# Step 4\n",
    "crime_df['Year'] = crime_df['Year'].astype(object)\n",
    "crime_df['Community_Area'] = crime_df['Community_Area'].astype(object)\n",
    "\n",
    "# Step 5\n",
    "crime_df['freq'] = crime_df.groupby('Primary_Type')['Primary_Type'].transform('count')\n",
    "crime_df = crime_df[crime_df.groupby('Primary_Type').freq.transform(len) > 1000]\n",
    "\n",
    "# Step 6\n",
    "crime_df = crime_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our initial pre-processing step, we see that there are 253,917 crimes and 17 unique crimes that occured over the course of 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations: (253917, 24)\n",
      "Number of Unique Crimes: 17\n"
     ]
    }
   ],
   "source": [
    "print('Number of Observations:', crime_df.shape)\n",
    "unique, counts = np.unique(crime_df.Primary_Type, return_counts = True)\n",
    "print('Number of Unique Crimes:',  len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Preparation**\n",
    "\n",
    "From exporing the data, many columns appear to be collinear to one another, and thus, inlcuding all predictors would be redundant, esecially when we consider the size of the dataset. For example, IURC (Illinois Unifrom Crime Reporting code) is said to be \"Directly linked to the Primary Type and Description\". Simiarly, FBI Code is a variable that describes the type of crime. Because our aim is to predict the type of crime (Primary_Type), we must remove any variables that may leak information about our primary outcome. \n",
    "\n",
    "**Step 1**, shows the data we decided to keep in our preliminary models.\n",
    "\n",
    "1. Select columns of interest - we keep **Primary_Type**, **Location_Description**, and **Community_Area**. \n",
    "\n",
    "After selecting our columns of interest, we further divide our dataset into inputs (crime_x) and our output variable (crime_y).\n",
    "\n",
    "2. Create x and y dataframes\n",
    "\n",
    "In **Steps 3 and 4** we process the x and y dataframes appropriately. All inputs in crime_x are one-hot encoded, while crime_y categorical values are recoded as numbers instead. Additonally, we save a list of column names (important for random forest feature selection).\n",
    "3. One-hot encode categorical inputs in crime_x - save column list\n",
    "4. Recode crime_y to convert categorical labels to numeric \n",
    "\n",
    "Next, we format data as arrays and reshape the y set.\n",
    "\n",
    "5. Convert dataframes to arrays and reshape crime_y\n",
    "\n",
    "Lastly, we shuffle and then split our x and y datasets into training and test sets, using a 75/25% split. Additionally, our primary outcome variable, Primary_Type, is stratified to ensure that each class of our outcome is proportionally represented in each dataset. \n",
    "\n",
    "6. Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [216672 197004  69363 ...  93958 202098  21907] TEST: [ 69014 221500  87887 ... 180517  50108  90883]\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "crime_model = crime_df[['Primary_Type', 'Location_Description', 'Beat', 'Arrest', 'Community_Area']]\n",
    "\n",
    "# Step 2\n",
    "crime_x = crime_model[['Location_Description', 'Year', 'Community_Area']]\n",
    "crime_y = crime_model[['Primary_Type']]\n",
    "\n",
    "# Step 3\n",
    "crime_x = pd.get_dummies(crime_x)\n",
    "crime_x_col_names = list(crime_x.columns.values) \n",
    "\n",
    "# Step 4\n",
    "crime_y.loc[:, 'Primary_Type'] = pd.factorize(crime_y['Primary_Type'])[0].reshape(-1,1)\n",
    "\n",
    "# Step 5\n",
    "crime_x = np.array(crime_x)\n",
    "crime_y = np.array(crime_y)\n",
    "\n",
    "crime_y = crime_y.reshape(-1)\n",
    "\n",
    "# Step 6\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\n",
    "sss.get_n_splits(crime_x, crime_y)\n",
    "\n",
    "for train_index, test_index in sss.split(crime_x, crime_y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = crime_x[train_index], crime_x[test_index]\n",
    "    y_train, y_test = crime_y[train_index], crime_y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions for Models**\n",
    "\n",
    "Functions adapated from: [github.com/geickelb](https://github.com/geickelb/HSIP442_guest_lecture/blob/master/notebooks/modeling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC Curve**\n",
    "\n",
    "This function will print an ROC Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View ROC Curve\n",
    "def ez_roc(model, x, y, pos_label=1):\n",
    "    \"\"\"prints a basic Recievor Operator Curve (ROC). \n",
    "\n",
    "    Keyword arguments:\n",
    "    model -- a 'fitted' sklearn model object \n",
    "    x -- predictor matrix (dtype='numpy array', required)\n",
    "    y -- outcome vector (dtype='numpy array', required)\n",
    "    pos_label --binary label considered positive in y  (dtype='int', default=1)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    model_name=type(model).__name__ # defining model name as the __name__ characteristic held by sklearn models\n",
    "\n",
    "    y_proba = model.predict_proba(x)[:,1]\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(y, y_proba, pos_label=pos_label)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('ROC curve')\n",
    "    ax1= plt.plot(fpr, tpr, 'b', label = '%s AUC = %0.3f' % (model_name, roc_auc), linewidth=2)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model**\n",
    "\n",
    "This function includes parameters for cross-fold validation and will return a plot of the area under the curve for each test. Additionally, as we are working with a multi-classification problem, we evaluate our logistic regression models with one-vs-one classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, y, cv = True):\n",
    "    \"\"\"prints common binary classification evaluation metrics and an ROC curve. \n",
    "\n",
    "    Keyword arguments:\n",
    "    model -- a 'fitted' sklearn model object \n",
    "    x -- predictor matrix (dtype='numpy array', required)\n",
    "    y -- outcome vector (dtype='numpy array', required)\n",
    "    cv -- if True, prints  score from 5-fold crossvalidation (dtype='boolean', default='True')\n",
    "    \"\"\"\n",
    "    import sklearn.metrics\n",
    "    from sklearn.metrics import log_loss, average_precision_score, precision_recall_curve\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    if cv==True:\n",
    "        cv_results= cross_val_score(model, x, y, scoring='roc_auc_ovo_weighted', cv=StratifiedKFold(5))\n",
    "        print(\"across 5 fold cv on trainingset, the model had \\n\", \n",
    "             \"mean auroc: {:0.3f}\".format(np.mean(cv_results)), \"\\n\",\n",
    "             \"std auroc: {:0.3f}\".format(np.std(cv_results))\n",
    "             )\n",
    "\n",
    "        base_cv_score=np.mean(cross_val_score(model, x, y, scoring='roc_auc_ovo_weighted', cv=StratifiedKFold(5)))\n",
    "\n",
    "    print(\"###metrics on provided dataset:###\")\n",
    "    \n",
    "    ##basic model performance\n",
    "    y_hat = model.predict(x) # predicted classes using default 0.5 threshold\n",
    "    y_proba = model.predict_proba(x)[:,] #predicted probabilities\n",
    "    auc=roc_auc_score(y, y_proba, multi_class = 'ovr', average = 'weighted')\n",
    "\n",
    "    print ('the AUC is: {:0.3f}'.format(auc))\n",
    "    print(\"classification report:\\n \", classification_report(y, y_hat, digits=3))\n",
    "\n",
    "    #ez_roc(model, x, y, pos_label = 1) #plotting roc curve\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest**\n",
    "\n",
    "This function includes parameters for stratified cross-fold validation and supports code for hyperparameter tuning for a random forest model. Because we are working with a multi-classification problem, we evaluate our logistic regression models with one-vs-one classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertuning_fxn(X, y, nfolds, model , param_grid, scoring = 'roc_auc_ovo_weighted', verbose=True, cv = True, \n",
    "                    return_train_score = True): \n",
    "    \"\"\"function that uses GridSearchCV to test a specified param_grid of hyperparameters and choose the optimal one based on nfolds cross-validation results. \n",
    "\n",
    "    Keyword arguments:\n",
    "    model -- a 'fitted' sklearn model object \n",
    "    X -- predictor matrix (dtype='numpy array', required)\n",
    "    y -- outcome vector (dtype='numpy array', required)\n",
    "    cv -- if True, prints a the roc_auc score from 10-fold crossvalidation (dtype='boolean', default='True')\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(12345)\n",
    "    \n",
    "    # The scorers can be either be one of the predefined metric strings or a scorer\n",
    "    # callable, like the one returned by make_scorer\n",
    "    #scoring = {'AUC': 'roc_auc_ovr', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator= model,\n",
    "                                     param_grid=param_grid,\n",
    "                                     cv=StratifiedKFold(nfolds), # stratified k-folds will preserve class balances - this function is what got the rest of the code to work with roc validation\n",
    "                                     scoring=scoring,\n",
    "                                     return_train_score=True,\n",
    "                                     n_jobs = -1)\n",
    "    \n",
    "    #scoring = {'accuracy': 'accuracy', 'auc': 'roc_auc_ovr'}\n",
    "    #scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "    \n",
    "    #OneVsRestClassifier(grid_search.fit(X, y))   \n",
    "    grid_search.fit(X, y)\n",
    "    print(\" scorer function: {}\".format(scoring))\n",
    "    print(\" ##### CV performance: mean & sd scores #####\")\n",
    "\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    \n",
    "    print('best cv score: {:0.3f}'.format(grid_search.best_score_))\n",
    "    print('best cv params: ', grid_search.best_params_)\n",
    "\n",
    "    worst_index=np.argmin(grid_search.cv_results_['mean_test_score'])\n",
    "    print('worst cv score: {:0.3f}'.format(grid_search.cv_results_['mean_test_score'][worst_index]))\n",
    "    print('worst cv params: ', grid_search.cv_results_['params'][worst_index])\n",
    "    ##\n",
    "    if verbose==True:\n",
    "        for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "    \n",
    "    return(grid_search)\n",
    "    #print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyses & Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Descriptives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Crimes**\n",
    "\n",
    "The top 10 crimes within the whole dataset included: \n",
    "\n",
    "1. Theft\n",
    "2. Battery\n",
    "3. Criminal Damage\n",
    "4. Narcotics\n",
    "5. Assault\n",
    "6. Other Offense\n",
    "7. Motor Vehicle Theft\n",
    "8. Deceptive Practice and Robbery.\n",
    "9. \n",
    "10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Primary_Type.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Crimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.Description.value_counts()\n",
    "crime_df.Primary_Type.value_counts() # much more descrition types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_desc10 = crime_df.Description.value_counts()\n",
    "crime_desc10 = crime_desc10.head(10)\n",
    "\n",
    "crime_desc10 = pd.DataFrame(crime_desc10)\n",
    "\n",
    "plt1 = crime_desc10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Crime Descriptions (Overall)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Crimes and Descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Primary_Type_Description.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 85)\n",
    "plt1.set_title(\"Top 10 Primary Crimes & Descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Crime Locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Location_Description.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Districts**\n",
    "\n",
    "**Where do these map to?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.District.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Districts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Communities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Community_Area.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression**\n",
    "\n",
    "Logistic regression was performed with an l2 penality and with solver = 'sag' (Stochastic Average Gradient descent), which can minimize the cost function more quickly for large datasets. Predictions were made using One vs One (OVO) multi-classification which compares each pair-wise class. \n",
    "\n",
    "Through 5-cross fold validation with the training set, our average AUC was 0.764. \n",
    "\n",
    "We also print out a classification report from one of the folds which includes the precision, recall, f1-score, and support (# of samples), for each outcome. We see that outcome 4 (X) had the highest recall (0.700), f1-score (0.502). It however, also had the highest number of observations (46,220). Class 0 (X) had the highest precision (0.538), however a very small recall and f1-score (0.007 and 0.014 respectively). These results make more sense in light of the fact that there were < 1000 observations in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation of Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across 5 fold cv on trainingset, the model had \n",
      " mean auroc: 0.746 \n",
      " std auroc: 0.001\n",
      "###metrics on provided dataset:###\n",
      "the AUC is: 0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0      0.538     0.007     0.014       970\n",
      "           1      0.125     0.001     0.001      1716\n",
      "           2      0.319     0.627     0.423     37099\n",
      "           3      0.258     0.004     0.007     15445\n",
      "           4      0.392     0.700     0.502     46220\n",
      "           5      0.180     0.086     0.117     19951\n",
      "           6      0.229     0.030     0.053      6733\n",
      "           7      0.262     0.014     0.027     12510\n",
      "           8      0.370     0.400     0.385     10664\n",
      "           9      0.231     0.002     0.003      5990\n",
      "          10      0.000     0.000     0.000      1159\n",
      "          11      0.351     0.014     0.027      5103\n",
      "          12      0.345     0.248     0.288     12815\n",
      "          13      0.435     0.145     0.217      7219\n",
      "          14      0.241     0.010     0.019      4743\n",
      "          15      0.000     0.000     0.000       961\n",
      "          16      0.000     0.000     0.000      1139\n",
      "\n",
      "    accuracy                          0.349    190437\n",
      "   macro avg      0.252     0.135     0.123    190437\n",
      "weighted avg      0.309     0.349     0.271    190437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', solver='sag', random_state = 12345)\n",
    "#fit model\n",
    "lr.fit(X_train, y_train)\n",
    "#evaluate model (on training data)\n",
    "evaluate_model(lr, X_train, y_train, cv = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation of Testing Data**\n",
    "\n",
    "We obtained a final AUC of 0.738 on the testing set. This result is only slightly lower than the average AUC of the training set described above (0.738 vs 0.746). Similarly as to what was reported above, crime 4 (X) had the highest recall (0.71), while crime 0 (X) had the highest precision. We can see through the classification report that our model has a wide range of performance success/failure depending on the outcome of interst. However, when examining outcome 2, 4, and 8 which had the highest recall scores, we can notice that these classes also had the highest number of samples. Interestingly, class 3 and 5, have the fourth and fifth highest number of samples, however, their recalls are 0.001 and 0.080 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###metrics on provided dataset:###\n",
      "the AUC is: 0.738\n",
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.009     0.018       323\n",
      "           1      0.200     0.003     0.007       572\n",
      "           2      0.319     0.624     0.422     12367\n",
      "           3      0.092     0.001     0.002      5149\n",
      "           4      0.391     0.701     0.502     15407\n",
      "           5      0.169     0.080     0.109      6651\n",
      "           6      0.160     0.022     0.038      2245\n",
      "           7      0.198     0.010     0.020      4170\n",
      "           8      0.370     0.393     0.381      3555\n",
      "           9      0.100     0.001     0.001      1996\n",
      "          10      0.000     0.000     0.000       386\n",
      "          11      0.258     0.010     0.019      1701\n",
      "          12      0.339     0.249     0.287      4272\n",
      "          13      0.451     0.157     0.233      2406\n",
      "          14      0.304     0.013     0.025      1581\n",
      "          15      0.000     0.000     0.000       320\n",
      "          16      0.000     0.000     0.000       379\n",
      "\n",
      "    accuracy                          0.347     63480\n",
      "   macro avg      0.226     0.134     0.121     63480\n",
      "weighted avg      0.283     0.347     0.269     63480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(lr, X_test, y_test, cv = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**\n",
    "\n",
    "1. First, we specify a parameter grid where we explore models by changing a number of parameters including:  max_depth, min_samples_split, and min_samples_leaf\n",
    "\n",
    "2. We then instatiate a RandomForestClassifier with criterion 'entropy'\n",
    "\n",
    "3. We can call the previously defined hypertuning_fxn above, and perform 5 cross-fold valdiation on our crime data. Once again we assess classification performing using one-vs-one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reshape y data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set Hyperparameters and Run Models**\n",
    "\n",
    "Our hyperparameter searching identified that the best performing model had a cross-validation score of 0.733 and its parameters were set as follows:\n",
    "\n",
    "```max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " scorer function: roc_auc_ovo_weighted\n",
      " ##### CV performance: mean & sd scores #####\n",
      "best cv score: 0.733\n",
      "best cv params:  {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "worst cv score: 0.726\n",
      "worst cv params:  {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.726 (+/-0.002) for {'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.732 (+/-0.002) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.733 (+/-0.003) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.733 (+/-0.002) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.732 (+/-0.002) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.732 (+/-0.002) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.732 (+/-0.002) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.732 (+/-0.003) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.732 (+/-0.003) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "0.732 (+/-0.003) for {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto'] # 'auto' which is equivalent to sqrt(n_features)\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 10]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 5, 10]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "model = RandomForestClassifier(criterion='entropy', random_state=12345)\n",
    "rf_hyper = hypertuning_fxn(X_train, y_train, nfolds = 5, model = model , param_grid = param_grid, scoring = 'roc_auc_ovo_weighted', cv = True, return_train_score = True)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "run_time = t1 - t2\n",
    "print('Training Time in Minutes:', run_time/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Return the Best Estimator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=5,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=12345,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(rf_hyper.best_estimator_)\n",
    "rf = rf_hyper.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluation of Training Data**\n",
    "\n",
    "On our testing set, our best performing random forest model had an AUC of 0.732. Similar to our logistic regression models, class 4 had the highest recall (0.818). Class 8, had a precision of 0.635 and recall of 0.130, despite having a fairly high number of samples (10,664). Class 12 had the highest precision (0.741). Also, noteworthy, the majority of samples had virtually 0 recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###metrics on provided dataset:###\n",
      "the AUC is: 0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       970\n",
      "           1      0.000     0.000     0.000      1716\n",
      "           2      0.304     0.590     0.402     37099\n",
      "           3      0.000     0.000     0.000     15445\n",
      "           4      0.327     0.818     0.467     46220\n",
      "           5      0.000     0.000     0.000     19951\n",
      "           6      0.000     0.000     0.000      6733\n",
      "           7      0.000     0.000     0.000     12510\n",
      "           8      0.635     0.130     0.216     10664\n",
      "           9      0.000     0.000     0.000      5990\n",
      "          10      0.000     0.000     0.000      1159\n",
      "          11      0.000     0.000     0.000      5103\n",
      "          12      0.741     0.026     0.050     12815\n",
      "          13      0.494     0.011     0.022      7219\n",
      "          14      0.000     0.000     0.000      4743\n",
      "          15      0.000     0.000     0.000       961\n",
      "          16      0.000     0.000     0.000      1139\n",
      "\n",
      "    accuracy                          0.323    190437\n",
      "   macro avg      0.147     0.093     0.068    190437\n",
      "weighted avg      0.243     0.323     0.208    190437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_hyper.best_estimator_, X_train, y_train, cv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation of Testing Data**\n",
    "\n",
    "Our best performing random forest classifier achieved an AUC of 0.725 on the testing set. Comparing evaluation on the training and testing sets, we can see that our results are fairly similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###metrics on provided dataset:###\n",
      "the AUC is: 0.725\n",
      "classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       323\n",
      "           1      0.000     0.000     0.000       572\n",
      "           2      0.303     0.586     0.399     12367\n",
      "           3      0.000     0.000     0.000      5149\n",
      "           4      0.327     0.820     0.468     15407\n",
      "           5      0.000     0.000     0.000      6651\n",
      "           6      0.000     0.000     0.000      2245\n",
      "           7      0.000     0.000     0.000      4170\n",
      "           8      0.664     0.138     0.228      3555\n",
      "           9      0.000     0.000     0.000      1996\n",
      "          10      0.000     0.000     0.000       386\n",
      "          11      0.000     0.000     0.000      1701\n",
      "          12      0.726     0.029     0.055      4272\n",
      "          13      0.488     0.009     0.017      2406\n",
      "          14      0.000     0.000     0.000      1581\n",
      "          15      0.000     0.000     0.000       320\n",
      "          16      0.000     0.000     0.000       379\n",
      "\n",
      "    accuracy                          0.323     63480\n",
      "   macro avg      0.148     0.093     0.069     63480\n",
      "weighted avg      0.243     0.323     0.208     63480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_hyper.best_estimator_, X_test, y_test, cv = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf8ca028d0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create empty list\n",
    "feat_impts = [] \n",
    "# bind all rf estimators for each classifier \n",
    "for clf in rf_hyper.best_estimator_:\n",
    "    feat_impts.append(clf.feature_importances_)\n",
    "\n",
    "# calculate the mean of features across predictors\n",
    "feat = np.mean(feat_impts, axis=0)\n",
    "# create a list of features (predictor names)\n",
    "features = crime_x_col_names\n",
    "# add predictor names to the means\n",
    "feat_importances = pd.Series(feat, index = features)   \n",
    "\n",
    "# plot feature importance for nlargest means \n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Pre-processing for Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor from Numpy array\n",
    "xb = torch.from_numpy(X_train).double()\n",
    "yb = torch.from_numpy(y_train).double()\n",
    "trainloader = TensorDataset(xb, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define Neural Network Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(nn.Linear(210, 100),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(100, 50), \n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(50, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set Neural Network Hyper-parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr = learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_epochs = 100\n",
    "trainloader = torch.utils.data.DataLoader(trainloader, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation of Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training loss: 2.17560\n",
      "Epoch 2/100, Training loss: 2.02907\n",
      "Epoch 3/100, Training loss: 2.00687\n",
      "Epoch 4/100, Training loss: 1.99680\n",
      "Epoch 5/100, Training loss: 1.98991\n",
      "Epoch 6/100, Training loss: 1.98465\n",
      "Epoch 7/100, Training loss: 1.98012\n",
      "Epoch 8/100, Training loss: 1.97666\n",
      "Epoch 9/100, Training loss: 1.97359\n",
      "Epoch 10/100, Training loss: 1.97093\n",
      "Epoch 11/100, Training loss: 1.96868\n",
      "Epoch 12/100, Training loss: 1.96705\n",
      "Epoch 13/100, Training loss: 1.96491\n",
      "Epoch 14/100, Training loss: 1.96348\n",
      "Epoch 15/100, Training loss: 1.96184\n",
      "Epoch 16/100, Training loss: 1.96074\n",
      "Epoch 17/100, Training loss: 1.95957\n",
      "Epoch 18/100, Training loss: 1.95847\n",
      "Epoch 19/100, Training loss: 1.95714\n",
      "Epoch 20/100, Training loss: 1.95622\n",
      "Epoch 21/100, Training loss: 1.95528\n",
      "Epoch 22/100, Training loss: 1.95447\n",
      "Epoch 23/100, Training loss: 1.95333\n",
      "Epoch 24/100, Training loss: 1.95250\n",
      "Epoch 25/100, Training loss: 1.95150\n",
      "Epoch 26/100, Training loss: 1.95077\n",
      "Epoch 27/100, Training loss: 1.95000\n",
      "Epoch 28/100, Training loss: 1.94959\n",
      "Epoch 29/100, Training loss: 1.94859\n",
      "Epoch 30/100, Training loss: 1.94805\n",
      "Epoch 31/100, Training loss: 1.94735\n",
      "Epoch 32/100, Training loss: 1.94668\n",
      "Epoch 33/100, Training loss: 1.94628\n",
      "Epoch 34/100, Training loss: 1.94546\n",
      "Epoch 35/100, Training loss: 1.94497\n",
      "Epoch 36/100, Training loss: 1.94416\n",
      "Epoch 37/100, Training loss: 1.94369\n",
      "Epoch 38/100, Training loss: 1.94313\n",
      "Epoch 39/100, Training loss: 1.94282\n",
      "Epoch 40/100, Training loss: 1.94220\n",
      "Epoch 41/100, Training loss: 1.94178\n",
      "Epoch 42/100, Training loss: 1.94097\n",
      "Epoch 43/100, Training loss: 1.94104\n",
      "Epoch 44/100, Training loss: 1.94033\n",
      "Epoch 45/100, Training loss: 1.93973\n",
      "Epoch 46/100, Training loss: 1.93936\n",
      "Epoch 47/100, Training loss: 1.93867\n",
      "Epoch 48/100, Training loss: 1.93848\n",
      "Epoch 49/100, Training loss: 1.93811\n",
      "Epoch 50/100, Training loss: 1.93783\n",
      "Epoch 51/100, Training loss: 1.93698\n",
      "Epoch 52/100, Training loss: 1.93678\n",
      "Epoch 53/100, Training loss: 1.93633\n",
      "Epoch 54/100, Training loss: 1.93586\n",
      "Epoch 55/100, Training loss: 1.93542\n",
      "Epoch 56/100, Training loss: 1.93537\n",
      "Epoch 57/100, Training loss: 1.93468\n",
      "Epoch 58/100, Training loss: 1.93453\n",
      "Epoch 59/100, Training loss: 1.93411\n",
      "Epoch 60/100, Training loss: 1.93377\n",
      "Epoch 61/100, Training loss: 1.93330\n",
      "Epoch 62/100, Training loss: 1.93284\n",
      "Epoch 63/100, Training loss: 1.93269\n",
      "Epoch 64/100, Training loss: 1.93211\n",
      "Epoch 65/100, Training loss: 1.93177\n",
      "Epoch 66/100, Training loss: 1.93156\n",
      "Epoch 67/100, Training loss: 1.93132\n",
      "Epoch 68/100, Training loss: 1.93068\n",
      "Epoch 69/100, Training loss: 1.93062\n",
      "Epoch 70/100, Training loss: 1.92994\n",
      "Epoch 71/100, Training loss: 1.92977\n",
      "Epoch 72/100, Training loss: 1.92949\n",
      "Epoch 73/100, Training loss: 1.92923\n",
      "Epoch 74/100, Training loss: 1.92898\n",
      "Epoch 75/100, Training loss: 1.92845\n",
      "Epoch 76/100, Training loss: 1.92807\n",
      "Epoch 77/100, Training loss: 1.92802\n",
      "Epoch 78/100, Training loss: 1.92793\n",
      "Epoch 79/100, Training loss: 1.92743\n",
      "Epoch 80/100, Training loss: 1.92712\n",
      "Epoch 81/100, Training loss: 1.92705\n",
      "Epoch 82/100, Training loss: 1.92658\n",
      "Epoch 83/100, Training loss: 1.92617\n",
      "Epoch 84/100, Training loss: 1.92621\n",
      "Epoch 85/100, Training loss: 1.92568\n",
      "Epoch 86/100, Training loss: 1.92524\n",
      "Epoch 87/100, Training loss: 1.92560\n",
      "Epoch 88/100, Training loss: 1.92476\n",
      "Epoch 89/100, Training loss: 1.92479\n",
      "Epoch 90/100, Training loss: 1.92471\n",
      "Epoch 91/100, Training loss: 1.92401\n",
      "Epoch 92/100, Training loss: 1.92361\n",
      "Epoch 93/100, Training loss: 1.92376\n",
      "Epoch 94/100, Training loss: 1.92350\n",
      "Epoch 95/100, Training loss: 1.92337\n",
      "Epoch 96/100, Training loss: 1.92294\n",
      "Epoch 97/100, Training loss: 1.92262\n",
      "Epoch 98/100, Training loss: 1.92244\n",
      "Epoch 99/100, Training loss: 1.92235\n",
      "Epoch 100/100, Training loss: 1.92191\n",
      "Train Loss (mean) 1.9450190921158201\n",
      "Train Accuracy 35.362323341434895\n",
      "Training time in minutes: -134.94674048026403\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# store running loss\n",
    "total_step = len(trainloader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "running_loss_res = []\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    # Define running loss as 0\n",
    "    running_loss = 0\n",
    "\n",
    "    # Run the model for each xb, yb in the trainloader.  \n",
    "    for i, (xb, yb) in enumerate(trainloader):\n",
    "        # clear gradients - otherwise they are stored\n",
    "        optimizer.zero_grad()\n",
    "        # Training pass\n",
    "        output = nn_model.forward(xb)\n",
    "        # caluclate loss calculated from the model output compared to the labels\n",
    "        loss = criterion(output, yb.long()) \n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "        # step function to update the weights\n",
    "        optimizer.step()\n",
    "        # record losses\n",
    "        loss_list.append(loss.item()) \n",
    "        \n",
    "        # Track the accuracy\n",
    "        total = yb.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct = (predicted == yb).sum().item()\n",
    "        acc_list.append((correct /total)*100)\n",
    "\n",
    "        running_loss += loss.item() # loss.item() gets the scalar value held in the loss. \n",
    "        # += function: Adds the running_loss (0) with loss.item and assigns back to running_loss\n",
    "    else:\n",
    "        print(\"Epoch {}/{}, Training loss: {:.5f}\".format(e+1, n_epochs, running_loss/len(trainloader)))\n",
    "        \n",
    "        # append all running_losses\n",
    "        running_loss_res.append(running_loss/len(trainloader))\n",
    "        \n",
    "        \n",
    "t2 = time.time()\n",
    "run_time = t1-t2\n",
    "\n",
    "train_loss = np.mean(running_loss_res)\n",
    "train_accuracy = np.mean(acc_list)\n",
    "\n",
    "print('Train Loss (mean)', train_loss)\n",
    "print('Train Accuracy', train_accuracy)\n",
    "print('Training time in minutes:', run_time/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot Training Loss and Accuracy Over Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cfc9aa89e8>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAeH0lEQVR4nO3de3BcZ5nn8e/Td90lS7Jk62LnYsc2cWIHEzKY5bpkSGBIWKZmMgyQZaFSWwVLQmVqisnWLjVMbe3sFpsZsqQIgUAmbIBdSDIEyAIZNkBCLsSXxI7tOHYcX2RLtmzd763uZ//oI1lXu2VLafvo96nqsvqct7vfU0f+9avnvOccc3dERCS8IoXugIiILCwFvYhIyCnoRURCTkEvIhJyCnoRkZCLFboDM6mpqfGVK1cWuhsiIheNrVu3nnT32pnWXZBBv3LlSrZs2VLoboiIXDTM7NBs61S6EREJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkQhX09/x6H799rb3Q3RARuaCEKujv++3rPK2gFxGZJFRBn4hFGMlkC90NEZELSriCPhphZFRBLyIyUbiCPqagFxGZKlxBH40wrNKNiMgk4Qp6jehFRKYJXdCnNaIXEZkkXEGvg7EiItOEK+hVuhERmSZ8Qa/SjYjIJOEKepVuRESmCVfQq3QjIjJN6IJ+WEEvIjJJuII+qhq9iMhU4Qp6lW5ERKYJV9BHdcKUiMhU4Qp6jehFRKY5a9CbWZOZPWVme8xsl5ndPkObNWb2nJkNm9lfTVl30Mx2mtlLZrZlPjs/VSIWYTTrZLO+kB8jInJRieXRZhS40923mVkZsNXMnnT33RPadABfAG6e5T3e6+4nz7OvZ5WI5b63RjJZUpHoQn+ciMhF4awjendvdfdtwc+9wB6gYUqbE+7+IpBekF7mKRHNbY6mWIqInDanGr2ZrQQ2Ai/M4WUO/MrMtprZbWd479vMbIuZbWlvP7f7vibHRvQKehGRcXkHvZmVAo8Ad7h7zxw+Y7O7XwPcAHzOzN41UyN3v9/dN7n7ptra2jm8/WkTSzciIpKTV9CbWZxcyD/s7o/O5QPc/Vjw7wngMeDauXYyX/GoRvQiIlPlM+vGgAeAPe5+91ze3MxKggO4mFkJcD3wyrl0NB8JlW5ERKbJZ9bNZuCTwE4zeylYdhfQDODu95lZPbAFKAeyZnYHsA6oAR7LfVcQA77v7r+Y3004LaERvYjINGcNend/BrCztGkDGmdY1QNcfW5dmzvV6EVEpgvdmbGgEb2IyEShCvqkRvQiItOEKugT0dzZsBrRi4icFq6gV+lGRGSacAZ9JlPgnoiIXDhCFfTxaG5ykEb0IiKnhSroVboREZkuVEGfDA7G6uqVIiKnhSrox0b06YxuPCIiMiaUQa/SjYjIaaEK+mjEiEZMs25ERCYIVdBD7sJmGtGLiJwWvqCPKehFRCYKZ9DrWjciIuPCF/TRiKZXiohMEL6gV+lGRGSS8AW9DsaKiEwSvqBXjV5EZJJQBn1aQS8iMi58Qa/SjYjIJOELeh2MFRGZJJRBr+mVIiKnhTLodTBWROS00AV9UjV6EZFJQhf0cQW9iMgkoQt6lW5ERCYLZ9BrRC8iMi6UQa8TpkRETgtf0EcjpDNONqv7xoqIQBiDfuy+sRrVi4gAeQS9mTWZ2VNmtsfMdpnZ7TO0WWNmz5nZsJn91ZR1HzSzvWa238y+NJ+dn0lSQS8iMkksjzajwJ3uvs3MyoCtZvaku++e0KYD+AJw88QXmlkUuBf4ANACvGhmj0957bwaH9HrgKyICJDHiN7dW919W/BzL7AHaJjS5oS7vwikp7z8WmC/ux9w9xHgh8BN89LzWSSiCnoRkYnmVKM3s5XARuCFPF/SAByZ8LyFKV8SE977NjPbYmZb2tvb59KtSeIKehGRSfIOejMrBR4B7nD3nnxfNsOyGafDuPv97r7J3TfV1tbm261pdDBWRGSyvILezOLkQv5hd390Du/fAjRNeN4IHJvD6+dMNXoRkcnymXVjwAPAHne/e47v/yKwyswuMbMEcAvw+Ny7mb+xoNelikVEcvKZdbMZ+CSw08xeCpbdBTQDuPt9ZlYPbAHKgayZ3QGsc/ceM/s88EsgCnzH3XfN90ZMlAxq9Do7VkQk56xB7+7PMHOtfWKbNnJlmZnWPQE8cU69Owcq3YiITBbeM2MV9CIiQJiDXqUbEREgjEGvefQiIpOELuh1wpSIyGShC/qxi5oNq3QjIgKEMOh1MFZEZDIFvYhIyIUv6HXClIjIJKEL+lg0QsQ0ohcRGRO6oIdc+Ubz6EVEcsIZ9NGIRvQiIoFwBn0sqqtXiogEwhn0UdOIXkQkEM6gV41eRGRceIN+NFPoboiIXBBCHPQa0YuIQFiDPqrSjYjImHAGfSxCetQL3Q0RkQtCSIM+qqtXiogEwhn0OmFKRGRcKIM+qVk3IiLjQhn0mkcvInJaKIM+rjNjRUTGhTLoNY9eROS0cAZ9NKqgFxEJhDPoVaMXERkX2qBPZxx3nTQlIhLKoE+O3SBco3oRkXAG/dgNwlWnFxEJa9DHFPQiImPOGvRm1mRmT5nZHjPbZWa3z9DGzOweM9tvZjvM7JoJ6zJm9lLweHy+N2AmCZVuRETGxfJoMwrc6e7bzKwM2GpmT7r77gltbgBWBY+3A98I/gUYdPcN89nps4mrdCMiMu6sI3p3b3X3bcHPvcAeoGFKs5uAhzzneaDSzJbNe2/zpNKNiMhpc6rRm9lKYCPwwpRVDcCRCc9bOP1lkDKzLWb2vJndfIb3vi1ot6W9vX0u3Zpm7GDssIJeRCT/oDezUuAR4A5375m6eoaXjE1ib3b3TcDHgX80s8tmen93v9/dN7n7ptra2ny7NSNNrxQROS2voDezOLmQf9jdH52hSQvQNOF5I3AMwN3H/j0A/IbcXwQLaqx0k9aIXkQkr1k3BjwA7HH3u2dp9jjwqWD2zXVAt7u3mlmVmSWD96kBNgO7Z3mPeaNZNyIip+Uz62Yz8Elgp5m9FCy7C2gGcPf7gCeAG4H9wADw6aDdWuCbZpYl96Xy91Nm6ywInTAlInLaWYPe3Z9h5hr8xDYOfG6G5c8C68+5d+dIs25ERE4L95mxKt2IiIQ06DW9UkRkXDiDXqUbEZFx4Qx6HYwVERkXzqBXjV5EZFy4g14jehGRcAZ9LGKYQVojehGRcAa9mZGIRjSiFxEhpEEPufKNpleKiIQ46JOxiA7GiogQ4qAvTsToHRotdDdERAoutEF/WW0J+473FrobIiIFF9qgX7OsnP0n+nRAVkQWvfAGfX0Zo1nnwMm+QndFRKSgQhz05QC82qryjYgsbqEN+ktrS4hHjVfbFPQisriFNujj0QiX1ZbyatvU+5iLiCwuoQ16gLXLytmrEb2ILHKhDvor6sto7R6ieyBd6K6IiBRMqIN+TX0ZgMo3IrKohTzog5k3Kt+IyCIW6qCvK09SWRxX0IvIohbqoDczrqgrU+lGRBa1UAc95GbevNbWSzbrhe6KiEhBhD7or6gvo38kQ0vnYKG7IiJSEKEPes28EZHFLvRBv7puLOh1QFZEFqfQB31JMsaK6mJ2tHQXuisiIgUR+qAHeP+aOn772glO9Q0XuisiIm+6RRH0t1zbRDrjPLb9aKG7IiLypjtr0JtZk5k9ZWZ7zGyXmd0+Qxszs3vMbL+Z7TCzayasu9XM9gWPW+d7A/Kxuq6Ma5or+cEfDuOuaZYisrjkM6IfBe5097XAdcDnzGzdlDY3AKuCx23ANwDMbAnwZeDtwLXAl82sap76Pie3vK2Z19v72XqosxAfLyJSMGcNendvdfdtwc+9wB6gYUqzm4CHPOd5oNLMlgF/DDzp7h3u3gk8CXxwXrcgTx+6ahkliSg/fPFIIT5eRKRg5lSjN7OVwEbghSmrGoCJCdoSLJtt+UzvfZuZbTGzLe3t7XPpVl5KkjE+smE5P9/RSs+QLlssIotH3kFvZqXAI8Ad7j717COb4SV+huXTF7rf7+6b3H1TbW1tvt2akz9/WzOD6QyPv3RsQd5fRORClFfQm1mcXMg/7O6PztCkBWia8LwROHaG5QVxdWMFa+rLePDZg4xmsoXqhojImyqfWTcGPADscfe7Z2n2OPCpYPbNdUC3u7cCvwSuN7Oq4CDs9cGygjAzvviB1ew/0cf3/3C4UN0QEXlTxfJosxn4JLDTzF4Klt0FNAO4+33AE8CNwH5gAPh0sK7DzP4OeDF43VfcvWP+uj9316+r4x2XVXP3k6/xkauXU1mcKGR3REQWnF2I88o3bdrkW7ZsWbD339Paw4fueZpb37GSL//JWxbsc0RE3ixmttXdN820blGcGTvV2mXl3HJtM9977hD7T/QVujsiIgtqUQY9wJ0fWE1RPMrf/nSXbkoiIqG2aIO+ujTJX9+whqf3neRbTx8odHdERBbMog16gE+8vZkb19fz33+5l62HCnqMWERkwSzqoDcz/v5jV9FQWcTnv7+dzv6RQndJRGTeLeqgByhPxbn349dwqm+EL/6fl8ioXi8iIbPogx5gfWMF//lP1vGbve185ae7dCljEQmVfE6YWhQ+cd0KDp7s59vPvEHTkmI++68uLXSXRETmhYJ+grtuXMvRrkH+yxN7aKgs4ob1ywrdJRGR86bSzQSRiPEPf76BDU2V3P7Dl3j8ZV3lUkQufgr6KVLxKN/9t29jQ1MlX/jBdu777euq2YvIRU1BP4PK4gQPfeZaPnzVMv7+/77Kf/rJK6R1WWMRuUipRj+LVDzKPbdspKGqiG/+9gB723q59+PXsLQ8VeiuiYjMiUb0ZxCJGH9zw1q+dssGXjnaw4f+5zP84Q2dQSsiFxcFfR5u2tDAP39uM6XJGH/xref56i/3MjKqUo6IXBwU9Hm6or6Mn3x+MzdvaODrT+3nI19/hl3HugvdLRGRs1LQz0F5Ks7/+LOr+danNnGqf4Sbvv57vvLT3XQPpAvdNRGRWSnoz8EH1tXxqzvexZ++tZHvPvsG7/nqUzz03EGGRzOF7pqIyDSL8laC82nXsW7+7me7ef5AB0tKEvzZpib+8u3NNC0pLnTXRGQROdOtBBX088Dd+f3+U3zv+YM8ufs4Dty8oYE7r19NY5UCX0QW3pmCXvPo54GZ8c5VNbxzVQ2t3YM8+PuDPPjsQX6+o5Vb37GCz7zzUuorNP9eRApDI/oFcqxrkLuffI1HtrUAsPmyGj66sYEb1tdTnND3q4jML5VuCujgyX4e3X6Ux7a3cKRjkLJUjI9d08gnrlvB5UtLC909EQkJBf0FwN158WAnD79wiCd2tpLOOOsbKnj36lretbqWjc2VxKOaBCUi50ZBf4E52TfMj7a08Os9x9l+pItM1ilLxXj36lret2Yp715dS3VpstDdFJGLiIL+AtY9mObZ/Sd5au8JntrbTnvvMGZwVTDaf++apWxoqsTMCt1VEbmAKegvEtms88qxbn6zt53fvdbOtsOdZB0aKov40FXLuH5dHesbK0jGooXuqohcYBT0F6nugTT/suc4P9/ZytP72klnnGQswtVNlbxtZRVvW7mEt66ooiwVL3RXRaTAFPQh0D2Q5rkDp9hysIMXD3Wy62g3o1knYrCmvpyrmypY31DJhqZK1tSXEYmo1COymCjoQ2hgZJTth7v4wxsdbDvcyY6WbroHcxdXqy1L8p7Vtbz7ilreuqKK+vKUavwiIXdeZ8aa2XeADwMn3P3KGdZXAd8BLgOGgH/n7q8E6w4CvUAGGJ2tEzJ3xYkYmy+vYfPlNUBu+uaRjkFePNjBb15r55e72vjR1tzJWrVlSa5urOTtlyzhjy6rZu2ycqIa8YssGvmcovkg8HXgoVnW3wW85O4fNbM1wL3A+yesf6+7nzyvXspZmRnN1cU0Vxfzsbc2MprJ8sqxHl4+0sXLR7rYdriTf9lzHIDyVIwrGypYu6yctcvKubKhnMtrS4lpHr9IKJ016N39d2a28gxN1gH/NWj7qpmtNLM6dz8+P12UcxGLRtjQlKvZj2nrHuK5Ayd54UAHu1t7+F/PH2I4uFNWMhZhTX0ZzdUl1JUlqa9IsW55Odc0V5GKa5aPyMVsPi668jLwb4BnzOxaYAXQCBwHHPiVmTnwTXe/f7Y3MbPbgNsAmpub56FbMlV9RYqPbmzkoxsbARjNZDl4qp9dx3p45Wg3u471sLOliyd7hhhK574AErEI1zRXsr6hgubqElYsKeaypaUsr1DdX+RikdfB2GBE/7NZavTlwNeAjcBOYA3wWXd/2cyWu/sxM1sKPAn8B3f/3dk+TwdjC8vd6RpIs/1IJ8/uP8Xzb5xi3/G+8dE/QFkqxpr6MlbX5R6r6kq5tKaUmtKESkAiBbCglyl29x7g08EHGfBG8MDdjwX/njCzx4BrgbMGvRSWmVFVkuB9a+p435o6IHcy14neYQ6e6mf/iT72tvXyalsPP335GD1Do+OvjRjUlCZpXlLMlQ0VXN1UwVuWV9BYVaSrdooUyHn/zzOzSmDA3UeAzwK/c/ceMysBIu7eG/x8PfCV8/08KYxIxKivSFFfkeK6S6vHl7vnvgBeO97L4Y4BjncP0dYzxIH2fn744mEefPb0XwHVJQmaq4u5cnkF6xsruHJ5Bc3VxZQm9QUgspDymV75A+A9QI2ZtQBfBuIA7n4fsBZ4yMwywG7gM8FL64DHgjpuDPi+u/9ivjdACsvMqCtPUVc+/cYqo5ks+4LR/9GuQVo6BznQ3sdj24/yvecPjberKIrTWFXEiupiVgTHAWpKk1SVJKguSbC8sohETOUgkXOlE6bkTZfNOgdO9rOntYejXYMc7RykpXOAQx0DHOkYIJ2Z/DsZjRgrlhRzaW0JjVXF1JWnWFaRYlVdKavrynR5ZxF0K0G5wEQixuVLS2e88cpoJktbzxAd/SN09I9wsm+EQ8Fxgdfb+3jhQAe9w6ePCSRjEdYtL6eqOEE6kyWTdapLk6ypLxs/WNxQWaRLQsiipqCXC0osGqGxqviMN1XvGx6ltWuQPW297DjSxY6j3ZzoHSIaiRCLGNsOdfLTl4+Nt0/GIlxSU0LTkmKWliWpLUuyvKKI1fVlrK4r1UFiCT39hstFpzQZY1VdGavqyvjI1ctnbNMzlOa1tl72nejjQHsf+0/0cfjUAFsPddLRPzLezgyWliUpTcYoTcYoS8WpKU1QW5bMHScoTlBRnFu2pr6cEh04louQfmsllMpTcTatXMKmlUumrUtnsrR0DvLa8V72tvVypGOAgZEMfcOj9AylOXS4nxM9w5POG4Dc1NHVdWWsb6hgSWmC0kSM0lSMuvIUyyuLWF6RoqY0qTKRXHAU9LLoxKO5Us4lNSX88VvqZ2zj7vSPZOgaGKFrIM3xniF2tHSz/UgXT+1tp2cozciULwKARDTCssoUyyuKWFaZO2i8rKKIkmSUiBnRSG6W0hX1ZZTrPgLyJlHQi8zAzMbLOY1VcGVDBe9fWzepzcholt6hNG09Q7R2DXGse5CjXYMc6xriaOcAz79+iuO9w2SyM89sa6gsor4iRVE8SioeobwoTn0wo6i2LEVtWYLqkiRLy5M6jiDnRb89IucoEYtQXZqkujTJW5ZXzNgmk3VO9g0zOJIh485oxjnaNcCrbb282trLyb5hBkZGOdWfZfexnlm/GCqK4iyvLKKhMkVDZRHLgy+JVDxKUTxKSTLGiupiqksSugaRTKOgF1lAY6Waia6oLxu/tMRUmaxzqm+Y4z3DnOof5lTfCMd7g78YgpPOXnijg94Jl52YqCwZY0VNMUvLUlSXJFhSmqA8FZ9wsDlGeVGc8lScpiVFug3lIqGgF7mARCPG0vIUS2c403iinqE07b25vxSG0hl6htIcPDnAwVP9HDw1wPGeIXYf66Gjf4SRzPRjCWPqy1NcvrSUiqI40YgRixr1wTGE1XVl1JenKEpEScYi+kvhIqagF7kIlafieR/MHR7N0Dc0Su/4I03XYDp3gbrjuRPRWrsHyWSddMY53jPE6JTyUcSgLBWnsjhOZVGc8qI4FRMeY8+rihM0LynWNYwuMNoTIiGXjEVJlkapLk3m1X5kNMsbJ/t5ta2HU30jDKYzDIyM0jc0Stdgmq6B3BdFS+cg3YNpugfTMx5XqCyOU1eWYml5kiUlCWKRCNEIRCMRElEjHo2QjEeoryiisaqIpqoiakqTlKfimqI6zxT0IjJJIhbhivoyrqgvy6u9uzOYztAzOEp77zCHOwY43DFAS+cA7b3DtPfllo1mnKzn/moYzWYZGc0yPJqd9iURjRiVRXFS8eh4OammJMnyytz5CssqchfRG5uxlPXcsY3yohjLKop0P+QZKOhF5LyYGcWJGMWJGPUVKdY3zjwDaSZj9zlo6RzgaNcgp/py1zjqGBhhJPgSGBnN0t43zJZDnbTtaJ1WVpooHjUaKotorCqmviLF8ooUyXiUk33DnOwbwd25qrGCDU1VrFpaihm4526FF4sa8UiEeNRCd/McBb2IFMzE+xzMeNnFKcZmJbX1DNHWPcRIJkvEjIhB10Cawx25q6Ae7Rzk6X3tnOgdxj132Yya0gTpjPOzHa1n7pPBJTUlrKkvZ3VdGcsqc39B1JQmyGZhMJ1heDRDcSJGRVFuFlNxIkYyFrlgr6SqoBeRi8bEWUlXNZ69fTqTZTTjFCVO3+D+ZN8wLx/p4uCpAYxcsDuMH4zuG06z73gfO4928/OdZ/5SmKl/S0oS1Af3aMhdMynBkpIEFUVxihNRihMxUvEo8eA4RVlwGY1UPHr2DzhHCnoRCa14NMLU/KwpTU47y3k2Q+kMJ3qGOd47xMneYeLRCKl4lEQsQv/IKD2DaXoG07lRfjrLYDrDqb4R2nqGONIxwPbDnXQOjHCGatO46pIEl9aW8KN//45z2NIzU9CLiMwiFY/SXJ2bLnquMlmnezBN71CagZEM/cOjDI9mGclkSY9m6RpM09Y9RGv3EAt1IygFvYjIAhor5ywpSRSsDxfmkQMREZk3CnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQs4W6kys82Fm7cChc3x5DXByHrtzMViM2wyLc7sX4zbD4tzuuW7zCnevnWnFBRn058PMtrh7PhfCC43FuM2wOLd7MW4zLM7tns9tVulGRCTkFPQiIiEXxqC/v9AdKIDFuM2wOLd7MW4zLM7tnrdtDl2NXkREJgvjiF5ERCZQ0IuIhFxogt7MPmhme81sv5l9qdD9WShm1mRmT5nZHjPbZWa3B8uXmNmTZrYv+Leq0H2db2YWNbPtZvaz4PklZvZCsM3/28wKd2eHBWJmlWb2YzN7NdjnfxT2fW1mXwx+t18xsx+YWSqM+9rMvmNmJ8zslQnLZty3lnNPkG87zOyauXxWKILezKLAvcANwDrgL8xsXWF7tWBGgTvdfS1wHfC5YFu/BPza3VcBvw6eh83twJ4Jz/8b8A/BNncCnylIrxbW14BfuPsa4Gpy2x/afW1mDcAXgE3ufiUQBW4hnPv6QeCDU5bNtm9vAFYFj9uAb8zlg0IR9MC1wH53P+DuI8APgZsK3KcF4e6t7r4t+LmX3H/8BnLb+09Bs38Cbi5MDxeGmTUCHwK+HTw34H3Aj4MmYdzmcuBdwAMA7j7i7l2EfF+Tu8VpkZnFgGKglRDua3f/HdAxZfFs+/Ym4CHPeR6oNLNl+X5WWIK+ATgy4XlLsCzUzGwlsBF4Aahz91bIfRkASwvXswXxj8BfA9ngeTXQ5e6jwfMw7vNLgXbgu0HJ6ttmVkKI97W7HwW+ChwmF/DdwFbCv6/HzLZvzyvjwhL0NsOyUM8bNbNS4BHgDnfvKXR/FpKZfRg44e5bJy6eoWnY9nkMuAb4hrtvBPoJUZlmJkFN+ibgEmA5UEKubDFV2Pb12ZzX73tYgr4FaJrwvBE4VqC+LDgzi5ML+Yfd/dFg8fGxP+WCf08Uqn8LYDPwETM7SK4s9z5yI/zK4M97COc+bwFa3P2F4PmPyQV/mPf1vwbecPd2d08DjwLvIPz7esxs+/a8Mi4sQf8isCo4Mp8gd/Dm8QL3aUEEtekHgD3ufveEVY8DtwY/3wr85M3u20Jx979x90Z3X0lu3/4/d/9L4CngT4NmodpmAHdvA46Y2RXBovcDuwnxviZXsrnOzIqD3/WxbQ71vp5gtn37OPCpYPbNdUD3WIknL+4eigdwI/Aa8DrwHwvdnwXczneS+5NtB/BS8LiRXM3618C+4N8lhe7rAm3/e4CfBT9fCvwB2A/8CEgWun8LsL0bgC3B/v5noCrs+xr4W+BV4BXge0AyjPsa+AG54xBpciP2z8y2b8mVbu4N8m0nuVlJeX+WLoEgIhJyYSndiIjILBT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQ+///zr/8tCl4vgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "test = list(range(100)) # number of epochs\n",
    "plt.plot(test, running_loss_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluate the Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 34.790485192186516\n"
     ]
    }
   ],
   "source": [
    "# Convert arrays into tensors\n",
    "xb = torch.from_numpy(X_test).double()\n",
    "yb = torch.from_numpy(y_test).double()\n",
    "\n",
    "# Apply the model to the testing dataset\n",
    "# Thus will enable us to see the predictions for each class\n",
    "ps = nn_model(xb)\n",
    "\n",
    "# Obtain the top prediction\n",
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "# Drop the grad by using detach\n",
    "top_p = top_p.detach().numpy()\n",
    "top_class = top_class.detach().numpy()\n",
    "\n",
    "yb = yb.reshape(-1,1)\n",
    "\n",
    "# convert to integers\n",
    "top_class = top_class.astype(np.int)\n",
    "\n",
    "# convert to dataframe\n",
    "top_class = pd.DataFrame(top_class)\n",
    "yb = np.asarray(yb)\n",
    "yb = pd.DataFrame(yb)\n",
    "\n",
    "# change column names\n",
    "top_class.columns = [\"Predicted\"]\n",
    "yb.columns = [\"True Label\"]\n",
    "\n",
    "results = pd.merge(top_class, yb, left_index=True, right_index=True)\n",
    "\n",
    "results['Accurate'] = np.where(results['Predicted']==results['True Label'], 1, 0)\n",
    "\n",
    "print('Testing Accuracy:', sum(results.Accurate)/len(results)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63480,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two neighbors will bring the point itself, and then its next nearest neighbor\n",
    "neighbors = NearestNeighbors(n_neighbors = 2).fit()\n",
    "\n",
    "print(neighbors.head(10))\n",
    "\n",
    "# rebind the true labels for the test sets\n",
    "# convert list to dataframe?\n",
    "#neigh_df = pd.DataFrame(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cluster by Crime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "\n",
    "kmeans = KMeans(n_clusters = 17, init= 'k-means++', n_init = 10, random_state=0)\n",
    "kmeans.fit(X_train)\n",
    "k_labs = kmeans.labels_\n",
    "preds = kmeans.predict(X_test)\n",
    "\n",
    "print(adjusted_mutual_info(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cluster by Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 17, init= 'k-means++', n_init = 10, random_state=0)\n",
    "kmeans.fit(X_train)\n",
    "k_labs = kmeans.labels_\n",
    "preds = kmeans.predict(X_test)\n",
    "\n",
    "print(adjusted_mutual_info(preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In our analysis we found....\n",
    "\n",
    "Compare all results...can I make a nice table with these even if I import it into the notebook?\n",
    "\n",
    "**Maybe re-look at primary type description?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Impact\n",
    "\n",
    "This analysis benefits our understanding of where crimes are most likely to occur. Results from predictive models that can analyze data retrospectively, can be later used to prospectively motitor high-risk locations for specific crimes and faciliate implementation of protective measures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "This analysis only analyzes crimes that occured in 2019, however, the full dataset includes crimes from 2001-Present. Thus, while our analysis may be more representative due to recent crimes, it is likely that our model would improve by including more data from past years. Additionally, this analysis did little hyperparameter tuning and thus, while our models were fairly strong, it is likely that may improve with more rigourous testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "* Analyze.Explore data from 2001 onwards \n",
    "    - Can research the implementation of parallel processing to speed up data pre-processing and analysis\n",
    "* Evaluate models after rigourous hyperparameter tuning\n",
    "* Use machine and deep learning methods to identify which crimes/locations are harder to predict\n",
    "* Utalizing advanced neural network models such as Recurrent Neural Networks that can better delineate the trajectory of certain crimes overtime and perhaps seasonally, ie: is theft more likely to occur in winter months?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
