{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chicago Crime Analysis**\n",
    "\n",
    "**Author:** Meg Hutch\n",
    "\n",
    "**Date:** June 7, 2020\n",
    "\n",
    "**Data source:** Data was accessed from [data.cityofchicago](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2). \n",
    "\n",
    "As described on their website:\n",
    "> \"This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system.\"\n",
    "\n",
    "In this analysis several machine and deep learning methods are implemented to examine the utility of these advanced analytic methods in predicting crime in the city of Chicago. We also include exploratory sub-analyses of crimes reported during the historical civil unrests in late May 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df = pd.read_csv(r'C:\\\\Users\\\\User\\\\Box Sync/Projects/Chicago_Crime/Crimes_-_2001_to_present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_areas = pd.read_csv(r'C:\\\\Users\\\\User\\\\Box Sync/Projects/Chicago_Crime/CommAreas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(crime_df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.columns = crime_df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df[\"Primary_Type_Description\"] = crime_df[\"Primary_Type\"] + \" \" +  crime_df[\"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df['Year'] = crime_df['Year'].astype(object)\n",
    "crime_df['Community_Area'] = crime_df['Community_Area'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_areas = crime_areas[['AREA_NUMBE','COMMUNITY']]\n",
    "#crime_areas = crime_areas.dropna()\n",
    "#crime_areas.columns =['Community_Area', 'Community_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '-' from the logintitude/latitude community_area entries\n",
    "#crime_areas = crime_areas[~crime_areas.Community_Area.str.contains(\"-\")]\n",
    "\n",
    "# transition the column to type 'float'\n",
    "#crime_df['Community_Area'] = crime_df['Community_Area'].astype(float)\n",
    "#crime_areas['Community_Area'] = crime_areas['Community_Area'].astype(float)\n",
    "\n",
    "# merge the seperate dataframes \n",
    "#crime_df = pd.merge(crime_df, crime_areas, on='Community_Area')\n",
    "#crime_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Descriptives**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the counts of variables - unique descriptions?\n",
    "* note: make sure to exclude colinear data: IUCR - explain why!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Crimes**\n",
    "\n",
    "The top 10 crimes included Theft, Battery, Criminal Damage, Narcotics, Assault, Other Offense, Motor Vehicle Theft, Deceptive Practice and Robbery.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Primary_Type.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Crimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df.Description.value_counts()\n",
    "crime_df.Primary_Type.value_counts() # much more descrition types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_desc10 = crime_df.Description.value_counts()\n",
    "crime_desc10 = crime_desc10.head(10)\n",
    "\n",
    "crime_desc10 = pd.DataFrame(crime_desc10)\n",
    "\n",
    "plt1 = crime_desc10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Crime Descriptions (Overall)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Crimes and Descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Primary_Type_Description.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 85)\n",
    "plt1.set_title(\"Top 10 Primary Crimes & Descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Crime Locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Location_Description.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Locations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Districts**\n",
    "\n",
    "**Where do these map to?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.District.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Districts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 Communities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_df10 = crime_df.Community_Area.value_counts()\n",
    "crime_df10 = crime_df10.head(10)\n",
    "\n",
    "crime_df10 = pd.DataFrame(crime_df10)\n",
    "\n",
    "plt1 = crime_df10.plot(kind=\"bar\", color = \"tomato\")\n",
    "plt1.tick_params(axis=\"x\", labelsize = 10, labelrotation = 90)\n",
    "plt1.set_title(\"Top 10 Communities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning Methods to Predict Crimes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score, auc, precision_recall_fscore_support, f1_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel \n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Process Data**\n",
    "\n",
    "(make sure that the Community_Name is okay...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_model = crime_df[['Primary_Type', 'Location_Description', 'Year', 'Community_Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "crime_m = crime_model.dropna()\n",
    "print(len(crime_model))\n",
    "print(len(crime_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing values\n",
    "crime_model = crime_model.dropna()\n",
    "crime_x = crime_model[['Location_Description', 'Year', 'Community_Area']]\n",
    "crime_y = crime_model[['Primary_Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_model['freq'] = crime_model.groupby('Primary_Type')['Primary_Type'].transform('count')\n",
    "crime_model = crime_model[crime_model.groupby('Primary_Type').freq.transform(len) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(crime_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_x = pd.get_dummies(crime_x)\n",
    "crime_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crime_y['Primary_Type'] = LabelEncoder().fit_transform(crime_y.Primary_Type)\n",
    "crime_y.loc[:, 'Primary_Type'] = pd.factorize(crime_y['Primary_Type'])[0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_y.Primary_Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\n",
    "sss.get_n_splits(crime_x, crime_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_x = np.asarray(crime_x)\n",
    "crime_y = np.asarray(crime_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(crime_x, crime_y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = crime_x[train_index], crime_x[test_index]\n",
    "    y_train, y_test = crime_y[train_index], crime_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique1, counts1 = np.unique(y_train, return_counts=True)\n",
    "print(counts1/len(y_train)*100)\n",
    "\n",
    "unique2, counts2 = np.unique(y_test, return_counts=True)\n",
    "print(counts2/len(y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model on training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x, y, cv = True):\n",
    "    \"\"\"prints common binary classification evaluation metrics and an ROC curve. \n",
    "\n",
    "    Keyword arguments:\n",
    "    model -- a 'fitted' sklearn model object \n",
    "    x -- predictor matrix (dtype='numpy array', required)\n",
    "    y -- outcome vector (dtype='numpy array', required)\n",
    "    cv -- if True, prints  score from 5-fold crossvalidation (dtype='boolean', default='True')\n",
    "    \"\"\"\n",
    "    import sklearn.metrics\n",
    "    from sklearn.metrics import log_loss, average_precision_score, precision_recall_curve\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    if cv==True:\n",
    "        cv_results= cross_val_score(model, x, y, scoring='roc_auc_ovo_weighted', cv=StratifiedKFold(5))\n",
    "        print(\"across 5 fold cv on trainingset, the model had \\n\", \n",
    "             \"mean auroc: {:0.3f}\".format(np.mean(cv_results)), \"\\n\",\n",
    "             \"std auroc: {:0.3f}\".format(np.std(cv_results))\n",
    "             )\n",
    "\n",
    "        base_cv_score=np.mean(cross_val_score(model, x, y, scoring='roc_auc_ovo_weighted', cv=StratifiedKFold(5)))\n",
    "\n",
    "    print(\"###metrics on provided dataset:###\")\n",
    "    ##basic model performance\n",
    "    y_hat = model.predict(x) # predicted classes using default 0.5 threshold\n",
    "    y_proba = model.predict_proba(x)[:,] #predicted probabilities\n",
    "    #errors = abs(y_hat - y)\n",
    "    #mape = 100 * np.mean(errors / y) # mean absolute percentage error\n",
    "    #accuracy = 100 - mape \n",
    "    auc=roc_auc_score(y, y_proba, multi_class = 'ovr', average = 'weighted')\n",
    "    #loss= log_loss(y, y_hat)\n",
    "\n",
    "    print ('the AUC is: {:0.3f}'.format(auc))\n",
    "    #print ('the logloss is: {:0.3f}'.format(loss))\n",
    "    print(\"confusion matrix:\\n \", confusion_matrix(y, y_hat))\n",
    "    print(\"classification report:\\n \", classification_report(y, y_hat, digits=3))\n",
    "\n",
    "    ez_roc(model, x, y, pos_label=1) #plotting roc curve\n",
    "    plt.show()\n",
    "    #ez_prc(model, x, y, pos_label=1) #plotting roc curve\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ez_roc(model, x, y, pos_label=1):\n",
    "    \"\"\"prints a basic Recievor Operator Curve (ROC). \n",
    "\n",
    "    Keyword arguments:\n",
    "    model -- a 'fitted' sklearn model object \n",
    "    x -- predictor matrix (dtype='numpy array', required)\n",
    "    y -- outcome vector (dtype='numpy array', required)\n",
    "    pos_label --binary label considered positive in y  (dtype='int', default=1)\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "    model_name=type(model).__name__ # defining model name as the __name__ characteristic held by sklearn models\n",
    "\n",
    "    y_proba = model.predict_proba(x)[:,1]\n",
    "        \n",
    "    fpr, tpr, thresholds = roc_curve(y, y_proba, pos_label=pos_label)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.title('ROC curve')\n",
    "    ax1= plt.plot(fpr, tpr, 'b', label = '%s AUC = %0.3f' % (model_name, roc_auc), linewidth=2)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[0:200000]\n",
    "y = y_train[0:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "to_remove = counts[(counts <= 10)]  \n",
    "to_remove\n",
    "# this drop them \n",
    "#to_remove = counts[~(counts <= 10)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= LogisticRegression(penalty='l2', solver='newton-cg', random_state = 12345)\n",
    "#fit model\n",
    "lr.fit(x, y)\n",
    "#evaluate model (on training data)\n",
    "evaluate_model(lr, x, y, cv = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model\n",
    "lr.fit(x, y)\n",
    "\n",
    "y_hat = lr.predict(x) # predicted classes using default 0.5 threshold\n",
    "y_proba = lr.predict_proba(x)[:,] #predicted probabilities\n",
    "\n",
    "roc_auc_score(y, y_proba, multi_class = 'ovo', average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "lr= LogisticRegression(penalty='l2', solver='newton-cg', random_state = 12345)\n",
    "#fit model\n",
    "lr.fit(X_train, y_train)\n",
    "#evaluate model (on training data)\n",
    "evaluate_model(lr, X_train, y_train, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lr.predict(X_train) # predicted classes using default 0.5 threshold\n",
    "y_proba = lr.predict_proba(X_train)[:,] #predicted probabilities\n",
    "evaluate_model(lr, X_train, y_train, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "lr= LogisticRegression(penalty='l2', solver='newton-cg', random_state = 12345)\n",
    "\n",
    "#fit model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_hat = lr.predict(mcTrain_x) # predicted classes using default 0.5 threshold\n",
    "y_proba = lr.predict_proba(mcTrain_x)[:,] #predicted probabilities\n",
    "\n",
    "roc_auc_score(mcTrain_y, y_proba, multi_class = 'ovo', average = 'weighted')\n",
    "\n",
    "#evaluate model (on training data)\n",
    "\n",
    "#evaluate_model(lr, mcTrain_x, mcTrain_y, cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split into training/test sets \n",
    "stratified k-folds\n",
    "cross fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to keep in the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "neigh.fit(X)\n",
    "NearestNeighbors(n_neighbors=2)\n",
    "\n",
    "## is there a way to validate these...check past homework assignment perhaps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-KNN\n",
    "\n",
    "-Logisitc Regression\n",
    "\n",
    "-Random Forest\n",
    "\n",
    "-PyTorch Neural Network\n",
    "\n",
    "-Crime location map\n",
    "\n",
    "-sub analysis since civil unrest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
